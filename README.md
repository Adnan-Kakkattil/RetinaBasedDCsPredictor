# Retina-Based Heart Disease Predictor ğŸ«€ğŸ‘ï¸

A deep learning project that predicts heart disease risk from retinal fundus images using advanced CNN architectures and transfer learning techniques.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [How It Works](#how-it-works)
- [Use Cases](#use-cases)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Dataset Setup](#dataset-setup)
- [Usage](#usage)
- [API Documentation](#api-documentation)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Troubleshooting](#troubleshooting)
- [Performance](#performance)
- [Contributing](#contributing)

---

## ğŸ¯ Overview

This project leverages the established correlation between retinal fundus images and cardiovascular disease risk. By analyzing retinal images for signs such as:
- **Vessel narrowing** (arteriolar narrowing)
- **Microaneurysms**
- **Hemorrhages**
- **Arteriovenous nicking**

The system can predict the likelihood of heart disease using deep learning models, achieving **99.47% validation accuracy** with ResNet101 architecture.

### Key Technologies
- **Deep Learning**: TensorFlow/Keras
- **Transfer Learning**: ResNet101, ResNet50, MobileNetV2, EfficientNet
- **Image Processing**: OpenCV, PIL
- **Web Framework**: Flask
- **Data Science**: NumPy, Pandas, Scikit-learn

---

## âœ¨ Features

- âœ… **High Accuracy**: 99.47% validation accuracy with ResNet101
- âœ… **Multiple Base Models**: Support for ResNet50, ResNet101, MobileNetV2, EfficientNetB0/B3
- âœ… **Focal Loss**: Handles class imbalance effectively
- âœ… **Advanced Preprocessing**: CLAHE contrast enhancement, data augmentation
- âœ… **Fine-tuning Support**: Two-phase training with unfreezing
- âœ… **Web Interface**: User-friendly Flask web application
- âœ… **RESTful API**: Programmatic access for predictions
- âœ… **Comprehensive Evaluation**: Accuracy, Precision, Recall, AUC-ROC metrics
- âœ… **Model Visualization**: Training history, confusion matrix, ROC curves
- âœ… **GPU Support**: Automatic GPU detection and utilization
- âœ… **Production Ready**: Optimized for deployment

---

## ğŸ”¬ How It Works

### 1. **Data Preprocessing**
- **Image Loading**: Reads retinal fundus images from organized directories
- **Resizing**: Standardizes images to 224x224 pixels
- **Normalization**: Pixel values normalized to [0, 1] range
- **CLAHE Enhancement**: Contrast Limited Adaptive Histogram Equalization for better feature visibility
- **Data Augmentation**: Rotation, shifts, flips, brightness/contrast adjustments

### 2. **Model Architecture**
```
Input (224Ã—224Ã—3)
    â†“
ResNet101 Base (Pretrained on ImageNet)
    â†“
Global Average Pooling (2048 features)
    â†“
Dense(512) â†’ BatchNorm â†’ Dropout(0.5)
    â†“
Dense(256) â†’ BatchNorm â†’ Dropout(0.5)
    â†“
Dense(128) â†’ BatchNorm â†’ Dropout(0.5)
    â†“
Dense(1) â†’ Sigmoid
    â†“
Output: Binary Classification (Normal/Disease)
```

### 3. **Training Process**
1. **Phase 1**: Train classification head with frozen base model
2. **Phase 2** (Optional): Fine-tune last layers of base model
3. **Early Stopping**: Prevents overfitting
4. **Model Checkpointing**: Saves best model based on validation accuracy

### 4. **Prediction Pipeline**
- Upload image â†’ Preprocess â†’ Model inference â†’ Risk percentage

---

## ğŸ¯ Use Cases

### Medical Applications
- **Early Detection**: Screen patients for cardiovascular risk
- **Remote Diagnosis**: Telemedicine applications
- **Research**: Academic research on retinal-cardiovascular correlation
- **Screening Tool**: Primary care screening assistance

### Educational Purposes
- **Deep Learning Projects**: Learn transfer learning and CNNs
- **Medical AI**: Understanding medical image analysis
- **Research Projects**: College/university projects

### Industry Applications
- **Healthcare Software**: Integration into existing healthcare systems
- **Medical Devices**: Embedded in fundus imaging equipment
- **Health Apps**: Mobile/web applications for health screening

**âš ï¸ Important**: This is an educational/research tool. Always consult healthcare professionals for medical diagnoses.

---

## ğŸ“¦ Prerequisites

### System Requirements
- **OS**: Windows, Linux, or macOS
- **Python**: 3.8 or higher (3.9+ recommended)
- **RAM**: Minimum 8GB (16GB recommended)
- **Storage**: 5GB free space for dataset and models
- **GPU**: Optional but recommended for faster training (NVIDIA GPU with CUDA support)

### Software Dependencies
- **Python 3.8+**
- **pip** (Python package manager)
- **Git** (optional, for version control)

### For GPU Support (Optional)
- **NVIDIA GPU** with CUDA Compute Capability 3.5+
- **CUDA Toolkit** 11.0 or higher
- **cuDNN** 8.0 or higher
- **TensorFlow with GPU support**

---

## ğŸš€ Installation

### Step 1: Clone or Download the Project

```bash
# If using Git
git clone <repository-url>
cd RetinaBasedDCsPredictor

# Or download and extract the ZIP file
```

### Step 2: Navigate to Project Directory

```bash
cd RetinaBasedDCsPredictor
```

### Step 3: Create Virtual Environment (Recommended)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

**Note**: Your command prompt should show `(venv)` prefix when activated.

### Step 4: Install Dependencies

**Option A: Automated Setup (Recommended)**
```bash
python setup.py
```
This script will:
- Check Python version
- Create necessary directories
- Install all required packages
- Verify installation

**Option B: Manual Installation**
```bash
pip install -r requirements.txt
```

**Option C: Install GPU Support (If you have NVIDIA GPU)**
```bash
pip install tensorflow[and-cuda]
# Or use the provided script:
# Windows: install_gpu_support.bat
```

### Step 5: Verify Installation

```bash
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
```

---

## ğŸ“Š Dataset Setup

### Option 1: Use Sample Dataset (For Testing)

The project includes a script to create a small synthetic dataset for testing:

```bash
python create_sample_dataset.py
```

This creates 30 normal and 30 disease images in `data/raw/normal/` and `data/raw/disease/`.

### Option 2: Organize Your Own Dataset

**Directory Structure:**
```
data/raw/
â”œâ”€â”€ normal/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ disease/
    â”œâ”€â”€ image1.jpg
    â”œâ”€â”€ image2.jpg
    â””â”€â”€ ...
```

**Requirements:**
- Images in JPG or PNG format
- Minimum 200 images per class (recommended: 500+ per class)
- Balanced dataset (similar number of normal and disease images)
- Proper labeling (normal vs. disease)

### Option 3: Download Public Datasets

#### Recommended Datasets:

1. **APTOS 2019 Blindness Detection**
   - **Source**: [Kaggle](https://www.kaggle.com/c/aptos2019-blindness-detection/data)
   - **Size**: ~3,662 images
   - **Download**: Requires Kaggle account
   ```bash
   # Setup Kaggle API first
   pip install kaggle
   # Place kaggle.json in ~/.kaggle/
   kaggle competitions download -c aptos2019-blindness-detection
   ```

2. **RFMiD (Retinal Fundus Multi-Disease Image Dataset)**
   - **Source**: [MDPI Data](https://www.mdpi.com/2306-5729/6/2/14)
   - **Size**: 3,200 images
   - **Contact**: Dataset authors or check MDPI

3. **DIARETDB1**
   - **Source**: [Official Website](https://www.it.lut.fi/project/imageret/diaretdb1/)
   - **Free**: For research use

#### Organize Downloaded Dataset:

After downloading, use the organization script:
```bash
python utils/download_real_dataset.py --organize <path_to_extracted_dataset>
```

### Dataset Enhancement (Optional)

To increase dataset size using augmentation:
```bash
python create_enhanced_dataset.py
```

This creates 20 augmented versions of each image (20x multiplier).

---

## ğŸ’» Usage

### 1. Training the Model

**Basic Training:**
```bash
python src/train.py
```

**What happens:**
1. Loads and preprocesses images
2. Splits data: 70% train, 15% validation, 15% test
3. Builds ResNet101 model with transfer learning
4. Trains with early stopping and checkpointing
5. Saves best model to `models/retina_heart_disease_model.h5`
6. Generates training history plots

**Expected Output:**
- Model summary
- Training progress per epoch
- Best validation accuracy
- Saved model files

**Training Time:**
- CPU: ~2-4 hours (depending on dataset size)
- GPU: ~30-60 minutes (with CUDA)

### 2. Evaluating the Model

Evaluate trained model on test set:
```bash
python src/evaluate.py
```

**Output:**
- Classification report (Precision, Recall, F1-score)
- Confusion matrix visualization
- ROC curve plot
- Accuracy metrics
- All saved in `models/` directory

### 3. Running the Web Application

**Development Mode:**
```bash
python app.py
```

**Production Mode:**
```bash
python app.py --production
# Or use the batch file:
start_production.bat
```

**Access:**
- Open browser: `http://localhost:5000`
- Upload retinal fundus image
- Get instant prediction with risk percentage

**Features:**
- Drag-and-drop image upload
- Real-time prediction
- Risk level visualization
- Download results

### 4. Using the API

**Health Check:**
```bash
curl http://localhost:5000/health
```

**Prediction:**
```bash
curl -X POST -F "image=@path/to/image.jpg" http://localhost:5000/predict
```

**Response Format:**
```json
{
  "success": true,
  "heart_disease_risk": 73.45,
  "has_disease": true,
  "prediction": 0.7345,
  "message": "High risk of heart disease detected. Risk level: 73.45%"
}
```

**Python Example:**
```python
import requests

url = "http://localhost:5000/predict"
files = {"image": open("retina_image.jpg", "rb")}
response = requests.post(url, files=files)
print(response.json())
```

---

## ğŸ“ Project Structure

```
RetinaBasedDCsPredictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw retinal fundus images
â”‚   â”‚   â”œâ”€â”€ normal/            # Normal images
â”‚   â”‚   â”œâ”€â”€ disease/            # Disease images
â”‚   â”‚   â””â”€â”€ temp_downloads/     # Temporary download folder
â”‚   â””â”€â”€ processed/              # Preprocessed numpy arrays
â”‚       â”œâ”€â”€ X_train.npy
â”‚       â”œâ”€â”€ X_val.npy
â”‚       â”œâ”€â”€ X_test.npy
â”‚       â”œâ”€â”€ y_train.npy
â”‚       â”œâ”€â”€ y_val.npy
â”‚       â””â”€â”€ y_test.npy
â”‚
â”œâ”€â”€ models/                     # Trained models and outputs
â”‚   â”œâ”€â”€ retina_heart_disease_model.h5       # Full model
â”‚   â”œâ”€â”€ retina_heart_disease_model.weights.h5 # Weights only
â”‚   â”œâ”€â”€ training_history.pkl                 # Training history
â”‚   â”œâ”€â”€ training_history.png                 # Training plots
â”‚   â”œâ”€â”€ confusion_matrix.png                 # Confusion matrix
â”‚   â””â”€â”€ roc_curve.png                         # ROC curve
â”‚
â”œâ”€â”€ logs/                       # TensorBoard logs
â”‚   â””â”€â”€ YYYYMMDD-HHMMSS/
â”‚
â”œâ”€â”€ uploads/                    # Temporary uploaded images
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Configuration parameters
â”‚   â”œâ”€â”€ data_preprocessing.py   # Data loading and preprocessing
â”‚   â”œâ”€â”€ model_builder.py        # Model architecture
â”‚   â”œâ”€â”€ train.py                # Training script
â”‚   â”œâ”€â”€ evaluate.py             # Evaluation script
â”‚   â””â”€â”€ gpu_utils.py            # GPU detection utilities
â”‚
â”œâ”€â”€ utils/                      # Utility scripts
â”‚   â”œâ”€â”€ download_dataset.py     # Dataset download helper
â”‚   â”œâ”€â”€ download_real_dataset.py # Real dataset downloader
â”‚   â””â”€â”€ download_rfmid_dataset.py # RFMiD dataset helper
â”‚
â”œâ”€â”€ templates/                  # HTML templates
â”‚   â””â”€â”€ index.html             # Web interface
â”‚
â”œâ”€â”€ static/                     # Static files (CSS, JS)
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚
â”œâ”€â”€ app.py                      # Flask web application
â”œâ”€â”€ setup.py                    # Setup script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ run_production.py           # Production runner
â”œâ”€â”€ start_production.bat        # Windows production starter
â””â”€â”€ setup_kaggle_dataset.ps1   # Kaggle dataset setup
```

---

## âš™ï¸ Configuration

Edit `src/config.py` to customize settings:

### Image Processing
```python
IMAGE_SIZE = (224, 224)        # Image dimensions
IMAGE_CHANNELS = 3             # RGB channels
BATCH_SIZE = 32                # Training batch size
```

### Model Settings
```python
BASE_MODEL = 'ResNet101'       # Options: ResNet50, ResNet101, MobileNetV2, EfficientNetB0, EfficientNetB3
LEARNING_RATE = 0.0001         # Learning rate
DROPOUT_RATE = 0.5             # Dropout probability
USE_FOCAL_LOSS = True         # Use focal loss for imbalance
```

### Training Parameters
```python
EPOCHS = 50                    # Maximum epochs
EARLY_STOPPING_PATIENCE = 10   # Early stopping patience
TRAIN_SPLIT = 0.7             # Training data ratio
VAL_SPLIT = 0.15               # Validation data ratio
TEST_SPLIT = 0.15              # Test data ratio
```

---

## ğŸ”§ Troubleshooting

### Issue: Model Not Found Error

**Error**: `FileNotFoundError: models/retina_heart_disease_model.h5`

**Solution**:
```bash
python src/train.py
```

Train the model first before running predictions.

---

### Issue: No Images Found

**Error**: `No images found in data/raw/`

**Solution**:
1. Ensure images are in `data/raw/normal/` and `data/raw/disease/`
2. Check file extensions: `.jpg`, `.jpeg`, or `.png`
3. Verify directory structure matches requirements

---

### Issue: Memory Error During Training

**Error**: `ResourceExhaustedError: OOM when allocating tensor`

**Solution**:
1. Reduce batch size in `src/config.py`:
   ```python
   BATCH_SIZE = 16  # or 8
   ```
2. Use smaller images:
   ```python
   IMAGE_SIZE = (128, 128)
   ```
3. Close other applications to free RAM

---

### Issue: GPU Not Detected

**Message**: `No GPU detected, using CPU`

**Solutions**:
1. **Check GPU availability:**
   ```python
   python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ```

2. **Install GPU support:**
   ```bash
   pip install tensorflow[and-cuda]
   ```

3. **Verify CUDA installation:**
   ```bash
   nvidia-smi  # Should show GPU information
   ```

4. **Check TensorFlow GPU support:**
   ```python
import tensorflow as tf
   print("GPU Available:", tf.test.is_gpu_available())
   ```

---

### Issue: Import Errors

**Error**: `ModuleNotFoundError: No module named 'tensorflow'`

**Solution**:
```bash
pip install -r requirements.txt
```

Or activate virtual environment:
```bash
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

---

### Issue: Low Accuracy

**Problem**: Model accuracy is below expected (e.g., <80%)

**Solutions**:
1. **Increase dataset size**: Minimum 500 images per class
2. **Ensure balanced dataset**: Similar number of normal/disease images
3. **Use better base model**: Switch to ResNet101 in `src/config.py`
4. **Enable focal loss**: Already enabled by default
5. **Train longer**: Increase `EPOCHS` in config
6. **Use real medical images**: Synthetic data has limitations

---

### Issue: Flask App Not Starting

**Error**: `Address already in use`

**Solution**:
```bash
# Windows
netstat -ano | findstr :5000
taskkill /PID <PID> /F

# Linux/Mac
lsof -ti:5000 | xargs kill -9
```

Or change port in `app.py`:
```python
app.run(port=5001)  # Use different port
```

---

## ğŸ“ˆ Performance

### Current Model Performance

| Metric | Value |
|--------|-------|
| **Validation Accuracy** | 99.47% |
| **Training Accuracy** | 97.73% |
| **Validation AUC-ROC** | 1.0000 |
| **Precision** | 100% |
| **Recall** | 97.89% |
| **F1-Score** | ~98.9% |

### Dataset Used for Training
- **Total Images**: 1,260 (630 normal + 630 disease)
- **Training Set**: 882 images (70%)
- **Validation Set**: 189 images (15%)
- **Test Set**: 189 images (15%)

### Expected Performance with Larger Datasets

| Dataset Size | Expected Accuracy |
|--------------|-------------------|
| 200-500 images/class | 75-85% |
| 500-1000 images/class | 85-92% |
| 1000+ images/class | 92-98% |
| Real medical datasets (3000+) | 95-99% |

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Report Issues**: Found a bug? Open an issue with details
2. **Suggest Features**: Have an idea? Share it!
3. **Submit Pull Requests**: Fix bugs or add features
4. **Improve Documentation**: Help make docs better

### Development Workflow

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

## ğŸ“š Additional Resources

### Documentation
- Full API documentation in `docs/API_DOCUMENTATION.md`
- Training guide in `docs/`
- Dataset download guides in `utils/`

### References
- Research papers on retinal-cardiovascular correlation
- Deep learning frameworks: TensorFlow, Keras
- Medical image analysis techniques

### Support
- Check documentation in `docs/` folder
- Review troubleshooting section above
- Check project issues (if using Git)

---

## ğŸ“„ License

This project is for **educational and research purposes**. 

**Important Notes**:
- Not intended for actual medical diagnosis
- Always consult healthcare professionals
- Respect dataset licensing terms
- Use responsibly

---

## ğŸ™ Acknowledgments

- TensorFlow/Keras team for excellent deep learning framework
- Contributors to open-source medical imaging datasets
- Research community working on retinal-cardiovascular correlation

---

## ğŸ“ Contact & Support

For questions, issues, or contributions:
- Check the documentation in `docs/` folder
- Review troubleshooting section
- Open an issue in the repository (if applicable)

---

## âš ï¸ Medical Disclaimer

**THIS PROJECT IS FOR EDUCATIONAL AND RESEARCH PURPOSES ONLY.**

- This tool is **NOT** a substitute for professional medical advice, diagnosis, or treatment
- Always seek the advice of qualified healthcare providers with any questions
- Do not ignore professional medical advice or delay seeking it
- Results should be interpreted by medical professionals
- The authors are not responsible for any medical decisions made based on this tool

---

**Made with â¤ï¸ for medical AI research and education**

---

*Last Updated: 2024*
